from ragflow_sdk import RAGFlow
import time
import os
from dotenv import load_dotenv
import json
import random
from deepeval.metrics import (
    ContextualPrecisionMetric,
    ContextualRecallMetric,
    ContextualRelevancyMetric,
    AnswerRelevancyMetric,
    FaithfulnessMetric
)
from deepeval.test_case import LLMTestCase
from requests.exceptions import ConnectionError

# Load environment variables from .env file
load_dotenv()

# Configuration
MAX_RETRIES = 20  # Maximum number of retries on failure
RETRY_DELAY = 5  # Delay between retries in seconds

def initialize_ragflow():
    """Initialize RAGFlow objects."""
    try:
        rag_object = RAGFlow(api_key=os.getenv('RAGFLOW_API_KEY'), base_url="http://127.0.0.1:9380")
        dataset = rag_object.list_datasets()[0]
        # Instead of returning a session, we return the chat assistant so that we can create a new session for each question.
        assistant = rag_object.list_chats()[0]
        return rag_object, dataset, assistant
    except Exception as e:
        print(f"Error initializing RAGFlow: {e}")
        return None, None, None
import re

def clean_output(text):
    # Remove markdown bold/italic symbols
    text = re.sub(r'\*\*', '', text)   # Remove bold markers
    text = re.sub(r'\*', '', text)      # Remove any remaining asterisks
    # Remove special tokens like "##3$$", "##2$$", "##1$$"
    text = re.sub(r'##\d+\$\$', '', text)
    # Optionally, trim extra whitespace
    return text.strip()


def get_response_with_retries(question, dataset_id):
    """Get response from the model with retry logic."""
    retries = 0
    while retries < MAX_RETRIES:
        try:
            response = rag_object.retrieve(question=question, dataset_ids=[dataset_id])
            return response
        except (ConnectionError, Exception) as e:
            print(f"Connection error: {e}. Retrying in {RETRY_DELAY} seconds...")
            retries += 1
            time.sleep(RETRY_DELAY)
    print(f"Failed to retrieve response for question after {MAX_RETRIES} attempts.")
    return []

# Initialize RAGFlow and get the assistant
rag_object, dataset, assistant = initialize_ragflow()

if rag_object is None or dataset is None or assistant is None:
    print("Failed to initialize RAGFlow. Exiting.")
    exit(1)

# Load questions from the JSON file
json_path = "ragflow_python/src/QA_pairs_v1.json"  # Ensure the file path is correct relative to your script
with open(json_path, "r") as f:
    data = json.load(f)
# data = data[:5]  # Only use the top 5 rows for testing

# Prepare the test cases list
test_cases = []

for i, item in enumerate(data):
    question = item.get("question", "")
    expected_output = item.get("expected answer", "")

    print(f"Question {i+1}: {question}")

    # Create a new session for each question
    session = assistant.create_session(name=f"Session for question {i+1}")
    print(f"Created new session: {session.id}")
    print("Retrieve context")
    # Retrieve context (e.g., relevant chunks)
    response = get_response_with_retries(question, dataset.id)
    print("sleep 6")
    time.sleep(6)
    retrieval_context = [res.content for res in response[:3]]  # Get top 3 retrieval contexts
    print("Got retrieved chunks")
    
    # Get the final output from the new session
    print("Send question to session")
    final_answer = ""
    try:
        answers = list(session.ask(question=question, stream=False))
        print("Session return Answer")
        final_answer = answers[-1].content if answers else ""
        # Clean the final answer before printing and saving it
        final_answer = clean_output(final_answer)
        # Using non-streaming call; if you prefer streaming, adjust accordingly.
        # for ans in session.ask(question=question, stream=False):
        #     final_answer = ans.content  # only the last chunk is the final answer
        print(f"✅ Final Answer for Question {i+1}: {final_answer}")
        print("sleep 6")
        time.sleep(6)
    except KeyError as e:
        print(f"Error: {e}")
    print('-' * 120)  # Separator between questions

    # Prepare the test case object
    test_case = {
        "input_question": question,
        "actual_output": final_answer,
        "expected_output": expected_output,
        "retrieval_context": retrieval_context,
        "session_id": session.id  # optionally include the session id for tracking
    }
    test_cases.append(test_case)

# Save the test cases to a JSON file
output_json_path = "ragflow_python/src/test_cases_output.json"
with open(output_json_path, "w") as f:
    json.dump(test_cases, f, indent=2)
'''
the script writes the results to an output JSON file (e.g., test_cases_output.json). 
Each entry in this file contains the input question, 
the actual output generated by the system, 
the expected output (if provided), 
the retrieval context, 
and the session ID.
'''
print(f"✅ Test cases saved to {output_json_path}")
